{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import time\n",
    "import tqdm\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "from torchvision.models import mobilenet_v3_small, mobilenet_v3_large\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import timm  # PyTorch Image Models (timm) 라이브러리\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_all_files_in_directory(directory):\n",
    "    total_files = 0\n",
    "    # os.walk를 사용해 하위 디렉토리까지 모두 탐색\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        total_files += len(files)  # 현재 디렉토리의 파일 개수를 더함\n",
    "    return total_files\n",
    "\n",
    "# 디렉토리 경로 설정\n",
    "directory = '/kaggle/input/intel-image/seg_train/seg_train'\n",
    "\n",
    "# 파일 개수 출력\n",
    "file_count = count_all_files_in_directory(directory)\n",
    "print(f\"'{directory}' 이하의 모든 폴더의 파일 개수: {file_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_all_files_in_directory(directory):\n",
    "    total_files = 0\n",
    "    # os.walk를 사용해 하위 디렉토리까지 모두 탐색\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        total_files += len(files)  # 현재 디렉토리의 파일 개수를 더함\n",
    "    return total_files\n",
    "\n",
    "# 디렉토리 경로 설정\n",
    "directory = '/kaggle/input/intel-image/seg_test/seg_test'\n",
    "\n",
    "# 파일 개수 출력\n",
    "file_count = count_all_files_in_directory(directory)\n",
    "print(f\"'{directory}' 이하의 모든 폴더의 파일 개수: {file_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# 시드 설정 함수 정의\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # 여러 GPU 사용 시\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 시드 설정\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_and_shuffle_files(data_dir):\n",
    "    \"\"\"\n",
    "    주어진 디렉토리 내의 모든 파일을 수집하여 랜덤하게 섞어 반환.\n",
    "    하위 폴더에 있는 파일도 모두 포함.\n",
    "    \"\"\"\n",
    "    all_files = []\n",
    "    data_dir = '/kaggle/input/intel-image/seg_train/seg_train'\n",
    "    \n",
    "    # os.walk를 사용해 하위 폴더 내의 모든 파일을 수집\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            all_files.append(os.path.join(root, file))\n",
    "    \n",
    "    # 파일 리스트를 랜덤하게 섞음\n",
    "    random.shuffle(all_files)\n",
    "    \n",
    "    return all_files\n",
    "\n",
    "def split_data_files(data_dir, output_dir, train_ratio=0.8, seed=42):\n",
    "    \"\"\"\n",
    "    데이터를 학습(train)과 검증(valid)으로 분할하고, 데이터를 새 폴더에 저장합니다.\n",
    "    data_dir: 원본 데이터가 있는 폴더 경로\n",
    "    output_dir: 분할된 데이터를 저장할 폴더 경로\n",
    "    train_ratio: 학습 데이터 비율 (기본값: 0.8)\n",
    "    seed: 랜덤 시드 값\n",
    "    \"\"\"\n",
    "    # 랜덤 시드 고정\n",
    "    random.seed(seed)\n",
    "\n",
    "    # data_intel 폴더 생성\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 학습 및 검증 폴더 생성\n",
    "    train_output_dir = os.path.join(output_dir, 'train')\n",
    "    valid_output_dir = os.path.join(output_dir, 'valid')\n",
    "\n",
    "    os.makedirs(train_output_dir, exist_ok=True)\n",
    "    os.makedirs(valid_output_dir, exist_ok=True)\n",
    "\n",
    "    # 모든 파일을 수집하고 섞음\n",
    "    all_files = collect_and_shuffle_files(data_dir)\n",
    "    total_num = len(all_files)\n",
    "\n",
    "    # 학습 데이터와 검증 데이터로 분할\n",
    "    train_num = int(total_num * train_ratio)\n",
    "    train_files = all_files[:train_num]\n",
    "    valid_files = all_files[train_num:]\n",
    "\n",
    "    # 파일을 새로운 폴더로 복사\n",
    "    for file in train_files:\n",
    "        # 하위 폴더 구조를 유지하면서 복사\n",
    "        relative_path = os.path.relpath(file, data_dir)\n",
    "        train_dest_path = os.path.join(train_output_dir, relative_path)\n",
    "        os.makedirs(os.path.dirname(train_dest_path), exist_ok=True)\n",
    "        shutil.copy(file, train_dest_path)\n",
    "\n",
    "    for file in valid_files:\n",
    "        # 하위 폴더 구조를 유지하면서 복사\n",
    "        relative_path = os.path.relpath(file, data_dir)\n",
    "        valid_dest_path = os.path.join(valid_output_dir, relative_path)\n",
    "        os.makedirs(os.path.dirname(valid_dest_path), exist_ok=True)\n",
    "        shutil.copy(file, valid_dest_path)\n",
    "\n",
    "    print(f\"Train files: {len(train_files)}개\")\n",
    "    print(f\"Valid files: {len(valid_files)}개\")\n",
    "\n",
    "# 경로 설정\n",
    "train_data_dir = '/kaggle/input/intel-image/seg_train/seg_train'\n",
    "output_dir = 'data_intel/split_data'\n",
    "\n",
    "# 데이터 분할 및 저장\n",
    "split_data_files(train_data_dir, output_dir, train_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_and_shuffle_files(data_dir):\n",
    "    \"\"\"\n",
    "    주어진 디렉토리 내의 모든 파일을 수집하여 랜덤하게 섞어 반환.\n",
    "    하위 폴더에 있는 파일도 모두 포함.\n",
    "    \"\"\"\n",
    "    all_files = []\n",
    "    data_dir = '/kaggle/input/intel-image/seg_test/seg_test'\n",
    "    \n",
    "    # os.walk를 사용해 하위 폴더 내의 모든 파일을 수집\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            all_files.append(os.path.join(root, file))\n",
    "    \n",
    "    # 파일 리스트를 랜덤하게 섞음\n",
    "    random.shuffle(all_files)\n",
    "    \n",
    "    return all_files\n",
    "\n",
    "def split_test_files(data_dir, num_samples, seed=42):\n",
    "    \"\"\"\n",
    "    테스트 데이터를 랜덤하게 추출합니다.\n",
    "    data_dir: 원본 테스트 데이터가 있는 폴더 경로\n",
    "    num_samples: 랜덤하게 추출할 파일 개수\n",
    "    seed: 랜덤 시드 값\n",
    "    \"\"\"\n",
    "    # 랜덤 시드 고정\n",
    "    random.seed(seed)\n",
    "\n",
    "    # 모든 파일을 수집하고 섞음\n",
    "    all_files = collect_and_shuffle_files(data_dir)\n",
    "\n",
    "    # 요청된 개수만큼 파일을 랜덤하게 추출\n",
    "    if num_samples > len(all_files):\n",
    "        print(f\"Warning: 요청된 파일 개수({num_samples})가 실제 파일 수({len(all_files)})보다 큽니다.\")\n",
    "        num_samples = len(all_files)\n",
    "\n",
    "    selected_files = all_files[:num_samples]\n",
    "\n",
    "    return selected_files\n",
    "\n",
    "def copy_files_to_test_dir(selected_files, dest_dir, data_dir):\n",
    "    \"\"\"\n",
    "    선택된 테스트 파일을 지정된 디렉토리로 복사\n",
    "    selected_files: 선택된 파일 경로 리스트\n",
    "    dest_dir: 복사할 목적 디렉토리\n",
    "    data_dir: 원본 데이터 디렉토리 경로\n",
    "    \"\"\"\n",
    "    # 목적 폴더가 없으면 생성\n",
    "    if not os.path.exists(dest_dir):\n",
    "        os.makedirs(dest_dir)\n",
    "\n",
    "    for file in selected_files:\n",
    "        # 원본 폴더 구조를 유지하면서 파일 복사\n",
    "        relative_path = os.path.relpath(file, data_dir)\n",
    "        destination = os.path.join(dest_dir, relative_path)\n",
    "        \n",
    "        # 하위 디렉토리 생성\n",
    "        os.makedirs(os.path.dirname(destination), exist_ok=True)\n",
    "        \n",
    "        # 파일 복사\n",
    "        shutil.copy(file, destination)\n",
    "\n",
    "    print(f\"{len(selected_files)}개의 파일이 '{dest_dir}'에 복사되었습니다.\")\n",
    "\n",
    "# 경로 설정\n",
    "test_data_dir = '/kaggle/input/intel-image/seg_test/seg_test'  # 원본 테스트 데이터 경로\n",
    "split_data_test_dir = 'data_intel/split_data/test'  # 테스트 데이터를 복사할 경로\n",
    "\n",
    "# 테스트 데이터에서 랜덤하게 추출할 파일 수 설정\n",
    "num_samples = 1000  # 원하는 만큼 설정\n",
    "\n",
    "# 테스트 데이터에서 랜덤 파일 추출\n",
    "random_test_files = split_test_files(test_data_dir, num_samples)\n",
    "print(f\"Test files: {len(random_test_files)}개\")\n",
    "\n",
    "# 추출된 파일을 split_data/test 폴더로 복사\n",
    "copy_files_to_test_dir(random_test_files, split_data_test_dir, test_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class customDataset(Dataset):\n",
    "    def __init__(self, files, root_dir, mode, transform=None, class_to_idx=None):\n",
    "        \"\"\"\n",
    "        files: 파일 리스트\n",
    "        root_dir: 파일들이 있는 폴더 경로\n",
    "        mode: 'train' 또는 'test' 모드\n",
    "        transform: 이미지 변환 파이프라인\n",
    "        class_to_idx: 클래스 이름을 레이블로 변환하는 딕셔너리 (예: {'buildings': 0, 'forest': 1, ...})\n",
    "        \"\"\"\n",
    "        self.files = files\n",
    "        self.root_dir = root_dir\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.class_to_idx = class_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.files[idx])\n",
    "        img = Image.open(img_path).convert('RGB')  # RGB로 변환하여 이미지를 읽음\n",
    "\n",
    "        # 폴더 이름(클래스 이름)을 추출하여 레이블 설정\n",
    "        folder_name = os.path.basename(os.path.dirname(img_path))\n",
    "        label = self.class_to_idx[folder_name]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # 'train' 모드일 때는 이미지와 레이블 반환\n",
    "        if self.mode == 'train':\n",
    "            return img, np.array(label)\n",
    "\n",
    "        # 'test' 모드일 때는 이미지와 파일 이름 반환 (레이블 없음)\n",
    "        else:\n",
    "            return img, self.files[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        root_dir: 이미지 파일이 포함된 상위 디렉토리\n",
    "        transform: 이미지 전처리 및 변환을 위한 torchvision.transforms 객체\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # 모든 이미지 파일 경로를 저장\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # 클래스 이름을 인덱스로 변환하는 매핑 딕셔너리\n",
    "        self.class_to_idx = {'buildings': 0, 'forest': 1, 'glacier': 2, 'mountain': 3, 'sea': 4, 'street': 5}\n",
    "\n",
    "        # 디렉토리 내의 각 이미지 파일 경로와 해당 클래스 레이블을 저장\n",
    "        for class_name in os.listdir(root_dir):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            if os.path.isdir(class_dir):\n",
    "                for img_file in os.listdir(class_dir):\n",
    "                    if img_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        self.image_paths.append(os.path.join(class_dir, img_file))\n",
    "                        self.labels.append(self.class_to_idx[class_name])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # 파일 이름 추출\n",
    "        # filename = os.path.basename(img_path)\n",
    "        filename = img_path\n",
    "        \n",
    "        return image, label,filename  # 이미지와 해당 레이블 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 이미지 전처리 설정\n",
    "org_size = (256, 256)\n",
    "img_size = 224\n",
    "visual_transform = transforms.Compose([\n",
    "    transforms.Resize(org_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(img_size),\n",
    "    # 평균이 0.5 표준편차 0.5 (0~1사이의 실수)\n",
    "    transforms.ToTensor(),\n",
    "    ])\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(org_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(org_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 인스턴스화\n",
    "\n",
    "# Intel 데이터셋 경로 설정\n",
    "train_dir = 'data_intel/split_data/train'\n",
    "valid_dir = 'data_intel/split_data/valid'\n",
    "test_dir = 'data_intel/split_data/test'\n",
    "\n",
    "# 클래스별로 디렉토리가 나뉘어 있기 때문에 각 클래스 디렉토리에서 파일을 읽어와야 함\n",
    "class_to_idx = {'buildings': 0, 'forest': 1, 'glacier': 2, 'mountain': 3, 'sea': 4, 'street': 5}\n",
    "\n",
    "# 각 클래스별 파일 목록 수집\n",
    "train_files = {cls: os.listdir(os.path.join(train_dir, cls)) for cls in class_to_idx}\n",
    "valid_files = {cls: os.listdir(os.path.join(valid_dir, cls)) for cls in class_to_idx}\n",
    "\n",
    "\n",
    "# 데이터셋 생성 (클래스별로)\n",
    "visual_datasets = []\n",
    "train_datasets = []\n",
    "valid_datasets = []\n",
    "test_datasets = []\n",
    "\n",
    "for cls in class_to_idx:\n",
    "    visual_datasets.append(customDataset(train_files[cls], os.path.join(train_dir, cls), 'train', transform=visual_transform,class_to_idx=class_to_idx))\n",
    "    train_datasets.append(customDataset(train_files[cls], os.path.join(train_dir, cls), 'train', transform=train_transform,class_to_idx=class_to_idx))\n",
    "    valid_datasets.append(customDataset(valid_files[cls], os.path.join(valid_dir, cls), 'train', transform=train_transform,class_to_idx=class_to_idx))\n",
    "    # 테스트 데이터셋 생성\n",
    "test_dataset = CustomTestDataset(root_dir=test_dir, transform=test_transform)\n",
    "\n",
    "# 데이터셋 결합 (모든 클래스 통합)\n",
    "visual_dataset = ConcatDataset(visual_datasets)\n",
    "train_dataset = ConcatDataset(train_datasets)\n",
    "valid_dataset = ConcatDataset(valid_datasets)\n",
    "#test_dataset = ConcatDataset(test_datasets)\n",
    "\n",
    "# 데이터셋 크기 출력\n",
    "print(f\"visual dataset size: {len(visual_dataset)}\")\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Valid dataset size: {len(valid_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "print(class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로더 객체생성\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "visual_loader = DataLoader(visual_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 배치사이즈만큼의 이미지를 시각화함함\n",
    "images, labels = next(iter(visual_loader))\n",
    "classes ={0:'buildings',1:'forest', 2: 'glacier', 3:'mountain', 4: 'sea', 5: 'street' }\n",
    "\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "for i in range(batch_size):\n",
    "    #4행 8열\n",
    "    ax = fig.add_subplot(4, 8, i + 1)\n",
    "    ax.set_title(classes[labels[i].item()])\n",
    "    ax.axis('off')\n",
    "    #컬러 채널 순서를 재정렬\n",
    "    ax.imshow(images[i].permute(1, 2, 0))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# device 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# He 초기화를 적용하는 함수 정의\n",
    "def initialize_weights_he(module):\n",
    "    if isinstance(module, nn.Linear) or isinstance(module, nn.Conv2d):\n",
    "        torch.nn.init.kaiming_normal_(module.weight, nonlinearity='relu')\n",
    "        if module.bias is not None:\n",
    "            torch.nn.init.zeros_(module.bias)\n",
    "\n",
    "# 분류기 레이어를 수정하는 함수 정의\n",
    "def modify_classifier(model, num_features, num_classes, model_name):\n",
    "    \"\"\"모델의 분류기 레이어를 수정하고 He 초기화를 적용하는 함수\"\"\"\n",
    "    classifier = nn.Sequential(\n",
    "        nn.Linear(num_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(512, num_classes),\n",
    "    ).to(device)\n",
    "    \n",
    "    # He 초기화 적용\n",
    "    classifier.apply(initialize_weights_he)\n",
    "    \n",
    "    # 분류기 레이어에 학습 가능하도록 requires_grad 설정\n",
    "    for param in classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # 모델의 분류기 부분을 교체\n",
    "    if model_name in ['efficientNetB2', 'efficientNetB0']:\n",
    "        model._fc = classifier\n",
    "    elif model_name in ['MNV3_large', 'MNV3_small']:\n",
    "        model.classifier = classifier\n",
    "    elif model_name in ['RESNET50', 'RESNET18']:\n",
    "        model.fc = classifier\n",
    "\n",
    "    return model\n",
    "\n",
    "# 모델 생성 및 수정 함수\n",
    "def create_model(model_name, num_classes):\n",
    "    \"\"\"모델 생성 및 수정\"\"\"\n",
    "    if model_name == 'efficientNetB2':\n",
    "        model = EfficientNet.from_pretrained('efficientnet-b2')\n",
    "        num_features = model._fc.in_features\n",
    "    elif model_name == 'efficientNetB0':\n",
    "        model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        num_features = model._fc.in_features\n",
    "    elif model_name == 'MNV3_large':\n",
    "        model = torchvision.models.mobilenet_v3_large(pretrained=True)\n",
    "        num_features = model.classifier[0].in_features\n",
    "    elif model_name == 'MNV3_small':\n",
    "        model = torchvision.models.mobilenet_v3_small(pretrained=True)\n",
    "        num_features = model.classifier[0].in_features\n",
    "    elif model_name == 'RESNET50':\n",
    "        model = torchvision.models.resnet50(pretrained=True)\n",
    "        num_features = model.fc.in_features\n",
    "    elif model_name == 'RESNET18':\n",
    "        model = torchvision.models.resnet18(pretrained=True)\n",
    "        num_features = model.fc.in_features\n",
    "    else:\n",
    "        raise ValueError(f\"Model '{model_name}' not recognized.\")\n",
    "    \n",
    "    # 모든 파라미터 고정\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # 분류기 레이어 수정 및 학습 가능하게 설정\n",
    "    model = modify_classifier(model, num_features, num_classes, model_name).to(device)\n",
    "\n",
    "    # 모델을 GPU로 이동\n",
    "    model = model.to(device)\n",
    "\n",
    "    return model\n",
    "\n",
    "# 선택 가능한 모델 출력\n",
    "models = ['efficientNetB2', 'efficientNetB0', 'MNV3_large', 'MNV3_small', 'RESNET50', 'RESNET18']\n",
    "print(\"사용 가능한 모델:\")\n",
    "for model_name in models:\n",
    "    print(f\" - {model_name}\")\n",
    "\n",
    "# 다중 분류를 위한 클래스 수 설정\n",
    "num_classes = 6  # 예시: 6개의 클래스를 분류한다고 가정\n",
    "\n",
    "# 모델 선택\n",
    "selected_model_name = \"RESNET50\"  # 선택하려는 모델 이름\n",
    "\n",
    "# 모델 생성\n",
    "model = create_model(selected_model_name, num_classes)  # selected_model_name을 사용\n",
    "print(f\"선택된 모델: {selected_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping 클래스\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): 성능 개선이 없을 때 몇 번의 에포크까지 기다릴지.\n",
    "            verbose (bool): True일 경우 개선될 때마다 메시지 출력.\n",
    "            delta (float): 성능 개선으로 간주될 최소 변화량.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        # 처음에 호출됐을때는 best_score가 None이라서 초기값을 설정\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        # 지금까지의 best_scor\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''검증 손실이 감소하면 모델을 저장합니다.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "            torch.save(model.state_dict(), self.path)  # 모델 상태 저장\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 손실함수 및 옵티마이저 정의\n",
    "lr = 0.00001\n",
    "epochs = 15\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# 학습률 조정(loss를 기준으로 한다면 mode가 min/ accuracy를 기준으로 한다면 max로 수정한다.)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor = 0.5, patience = 3)\n",
    "\n",
    "# EarlyStopping 인스턴스 생성 (patience=10)\n",
    "path = f\"{selected_model_name}_best.pth\"\n",
    "early_stopping = EarlyStopping(patience=10, verbose=True, path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def imshow(img):\n",
    "    # 이미지 정규화를 해제하기 위해 역변환\n",
    "    img = img / 2 + 0.5  # (0.5, 0.5, 0.5)로 정규화된 이미지일 경우\n",
    "    np_img = img.numpy()\n",
    "    plt.imshow(np.transpose(np_img, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "def fit(model, criterion, optimizer, epochs, train_loader, valid_loader):\n",
    "    # 훈련 시작시 초기 lr을 로딩\n",
    "    pre_lr = optimizer.param_groups[0]['lr']\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    train_correct = 0\n",
    "\n",
    "    # 그래프를 출력하기 위해 리스트에 누적\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    valid_losses = []\n",
    "    valid_accuracies = []\n",
    "\n",
    "    for epoch in range(3):\n",
    "        start = time.time()\n",
    "\n",
    "        # tqdm을 사용하여 각 에포크의 진행률 표시\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\", leave=False)\n",
    "\n",
    "        # 1 epoch 중에 train에 해당하는 for 문\n",
    "        for train_x, train_y in train_loader_tqdm:\n",
    "            model.train()\n",
    "            train_x, train_y = train_x.to(device), train_y.to(device).long()\n",
    "            \n",
    "            # 레이블의 차원이 1D인지 확인 및 변환\n",
    "            # if train_y.dim() > 1:\n",
    "            #     train_y = train_y.squeeze()  # 레이블을 1D로 변환\n",
    "            # 기울기 초기화\n",
    "            optimizer.zero_grad()\n",
    "            # 예측\n",
    "            pred = model(train_x)\n",
    "            # 손실계산\n",
    "            loss = criterion(pred, train_y).squeeze()\n",
    "            # 오차역전파\n",
    "            loss.backward()\n",
    "            # 진행\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # 소프트맥스\n",
    "            y_pred = pred.argmax(dim=1).cpu()\n",
    "            # y_pred와 train_y값이 같으면 train_correct 추가\n",
    "            train_correct += y_pred.eq(train_y.cpu()).int().sum()\n",
    "\n",
    "        # validation data check\n",
    "        valid_loss = 0\n",
    "        valid_acc = 0\n",
    "        valid_correct = 0\n",
    "\n",
    "        # tqdm을 사용하여 각 에포크의 validation 진행률 표시\n",
    "        valid_loader_tqdm = tqdm(valid_loader, desc=f\"Epoch {epoch+1}/{epochs} [Validation]\", leave=False)\n",
    "\n",
    "        # 1 epoch 중에 validation에 해당하는 for 문\n",
    "        for valid_x, valid_y in valid_loader_tqdm:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                valid_x, valid_y = valid_x.to(device), valid_y.to(device).long()\n",
    "                # 레이블의 차원이 1D인지 확인 및 변환\n",
    "                # if valid_y.dim() > 1:\n",
    "                #     valid_y = valid_y.squeeze()  # 레이블을 1D로 변환\n",
    "                pred = model(valid_x)\n",
    "                loss = criterion(pred, valid_y).squeeze()\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            # 소프트맥스\n",
    "            y_pred = pred.argmax(dim=1).cpu()\n",
    "            valid_correct += y_pred.eq(valid_y.cpu()).int().sum()\n",
    "\n",
    "        train_acc = train_correct / len(train_loader.dataset)\n",
    "        valid_acc = valid_correct / len(valid_loader.dataset)\n",
    "\n",
    "        print(f'{time.time() - start:.3f}sec : [Epoch {epoch+1}/{epochs}] -> train loss: {train_loss/len(train_loader):.4f}, train acc: {train_acc*100:.3f}% / valid loss: {valid_loss/len(valid_loader):.4f}, valid acc: {valid_acc*100:.3f}%')\n",
    "        print('reserved:', round(torch.cuda.memory_reserved(0)/1024**2))\n",
    "        train_losses.append(train_loss/len(train_loader))\n",
    "        train_accuracies.append(train_acc)\n",
    "        valid_losses.append(valid_loss/len(valid_loader))\n",
    "        valid_accuracies.append(valid_acc)\n",
    "\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        train_correct = 0\n",
    "        \n",
    "            # ReduceLROnPlateau 스케줄러를 사용하여 검증 손실에 따라 학습률을 조정\n",
    "        scheduler.step(valid_loss)\n",
    "\n",
    "        # 현재 학습률 출력\n",
    "        now_lr = optimizer.param_groups[0]['lr']\n",
    "        if now_lr != pre_lr:\n",
    "            pre_lr = now_lr\n",
    "            lr_str = ', LR changed!!'\n",
    "        else:\n",
    "            lr_str = ''\n",
    "\n",
    "        print(f'learning_rate {epoch+1}: {now_lr:.8f}'+lr_str)\n",
    "\n",
    "        # EarlyStopping을 호출하여 학습 중단 여부 확인\n",
    "        early_stopping(valid_loss, model)\n",
    "\n",
    "        # 학습 중단 조건을 충족하면 break\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "        print('-' * 70)\n",
    "        \n",
    "    # 학습 및 검증 손실/정확도 시각화\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(valid_losses, label='Valid Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(valid_accuracies, label='Valid Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 클래스 인덱스와 이름 매핑\n",
    "class_to_idx = {'buildings': 0, 'forest': 1, 'glacier': 2, 'mountain': 3, 'sea': 4, 'street': 5}\n",
    "idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "# 혼동 행렬(Confusion Matrix) 그리는 함수\n",
    "def plot_confusion_matrix(labels, predictions, class_names):\n",
    "    cm = confusion_matrix(labels, predictions)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    \n",
    "# 테스트 데이터에서 성능을 평가하고, 예측이 잘못된 이미지를 시각화하는 함수\n",
    "def evaluate_and_visualize(model, test_loader, criterion):\n",
    "    test_loss = 0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    incorrect_labels = []\n",
    "    incorrect_preds = []\n",
    "    incorrect_filenames = []\n",
    "    all_labels = []  # 전체 실제 라벨 저장\n",
    "    all_preds = []   # 전체 예측 라벨 저장\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for test_x, test_y, filenames in tqdm(test_loader):\n",
    "            test_x, test_y = test_x.to(device), test_y.to(device).long()\n",
    "            pred = model(test_x)\n",
    "            loss = criterion(pred, test_y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # 예측 결과 처리\n",
    "            y_pred = pred.argmax(dim=1).cpu()  # 다중 분류를 위한 argmax 사용\n",
    "\n",
    "            # 정확도 계산\n",
    "            test_correct += y_pred.eq(test_y.cpu()).int().sum().item()\n",
    "            test_total += test_y.size(0)\n",
    "            \n",
    "            # 전체 라벨과 예측값 저장 (혼동 행렬을 위한 데이터)\n",
    "            all_labels.extend(test_y.cpu().numpy())\n",
    "            all_preds.extend(y_pred.cpu().numpy())\n",
    "\n",
    "            \n",
    "            # 잘못된 예측 저장 (각 요소별로 비교)\n",
    "            for i in range(len(y_pred)):\n",
    "                if y_pred[i] != test_y[i]:  # 예측과 실제가 다른 경우에만 저장\n",
    "                    incorrect_labels.append(test_y.cpu()[i].item())\n",
    "                    incorrect_preds.append(y_pred.cpu()[i].item())\n",
    "                    incorrect_filenames.append(filenames[i])\n",
    "                    \n",
    "\n",
    "    test_accuracy = test_correct / test_total\n",
    "    print(f\"test_correct: {test_correct}, test_total: {test_total}\")\n",
    "    print(f'Test Loss: {test_loss / len(test_loader):.4f}, Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "    \n",
    "    # 혼동 행렬 시각화\n",
    "    class_names = [idx_to_class[i] for i in range(len(class_to_idx))]\n",
    "    plot_confusion_matrix(all_labels, all_preds, class_names)\n",
    "    \n",
    "    # 잘못 예측된 파일 이름만 추출\n",
    "    just_filenames = [os.path.basename(path) for path in incorrect_filenames]\n",
    "\n",
    "    # 예측이 잘못된 이미지 시각화\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    for i in range(min(16, len(incorrect_filenames))):\n",
    "        ax = fig.add_subplot(4, 4, i + 1)\n",
    "        # 잘못된 예측된 이미지 불러오기\n",
    "        image = Image.open(incorrect_filenames[i])\n",
    "        ax.imshow(image)\n",
    "\n",
    "        # 실제 라벨과 예측 라벨 가져오기\n",
    "        true_label = idx_to_class[incorrect_labels[i]]\n",
    "        pred_label = idx_to_class[incorrect_preds[i]]\n",
    "        ax.set_title(f'Pred: {pred_label}, Label: {true_label}, {just_filenames[i]}', fontsize=10)\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(model, criterion, optimizer, epochs, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base 디렉토리 설정\n",
    "base_dir = os.getcwd()  # 현재 작업 디렉토리\n",
    "\n",
    "# base 디렉토리 아래에 'model' 폴더 경로 설정\n",
    "modelPath = os.path.join(base_dir, 'model_intel')\n",
    "\n",
    "# 폴더가 존재하지 않으면 생성\n",
    "if not os.path.exists(modelPath):\n",
    "    os.makedirs(modelPath)\n",
    "\n",
    "# 모델 파일 이름 설정\n",
    "# selected_model_name에 .pth 확장자를 추가\n",
    "selected_model_name = f\"{selected_model_name}.pth\" if not selected_model_name.endswith(\".pth\") else selected_model_name\n",
    "\n",
    "# 모델 저장\n",
    "torch.save(model.state_dict(), os.path.join(modelPath, selected_model_name))\n",
    "\n",
    "print(f\"Model saved to {os.path.join(modelPath, selected_model_name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_visualize(model, test_loader, criterion)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
